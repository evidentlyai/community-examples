{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab3eff6-f47f-4d94-aa8a-ecc6bc481048",
   "metadata": {},
   "source": [
    "# Evaluating LLMs on a Content Generation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf486f7-e148-466d-8e04-1845931fca87",
   "metadata": {},
   "source": [
    "* docs: https://docs.evidentlyai.com/introduction\n",
    "* repo: https://github.com/evidentlyai/evidently/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca2286-b128-4c8f-8e0b-358726dc0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install openai evidently tracely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee248f7-b453-46d6-90ba-7cb43f77c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a6e281-6655-4e9d-bd7a-d04cdc83b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_topics = [\n",
    "    \"testing in AI engineering is as important as in development\",\n",
    "    \"CI/CD is applicable in AI\",\n",
    "    \"Collaboration of subject matter experts and AI engineers improves product\",\n",
    "    \"Start LLM apps development from test cases generation\",\n",
    "    \"evidently is agreat for LLM testing, use it\" #here is a tiny mistake!\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3fedbb-3044-449b-aeb8-3a1e8a78a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OA_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9db106-6516-4e0a-a8a4-0d3fe82ee6dd",
   "metadata": {},
   "source": [
    "## Tracing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab5b67-4052-4902-99b1-3800ce6fea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.ui.workspace import CloudWorkspace\n",
    "\n",
    "from evidently import Dataset, DataDefinition, Report\n",
    "from evidently.descriptors import *\n",
    "from evidently.tests import lte, lt, gte, gt, eq, is_in\n",
    "from evidently.core.datasets import DescriptorTest\n",
    "from evidently.presets import TextEvals\n",
    "from evidently.llm.templates import BinaryClassificationPromptTemplate\n",
    "from evidently.presets.dataset_stats import ValueStatsTests\n",
    "from evidently.metrics import RowTestSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061ad24-6667-476e-a732-b4807371bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracely import get_info, init_tracing, trace_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d38f08-f197-4f76-9f1d-e597fc6edeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CloudWorkspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59825687-fdad-4d51-b26d-248cc1ba8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = client.create_project(\"Content Generation\",  org_id = \"ORG ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ba3a5-3f59-425a-b967-f3d627efe68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_tracing(\n",
    "    project_id=str(project.id), # Project ID from Evidently Cloud\n",
    "    export_name=\"content generation: basic\",\n",
    "    as_global=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc39598-4df0-4c5d-8006-cf3cc385ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae41329-f66f-48a1-b778-6cb179e1ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace_event()\n",
    "def tweet_generation(topic, model=\"gpt-3.5-turbo\", instructions=\"\"):\n",
    "    response = OA_client.responses.create(\n",
    "        instructions=instructions,\n",
    "        model=model,\n",
    "        input=f\"Write a paragraph about {topic}\"\n",
    "    )\n",
    "\n",
    "    text = response.output_text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de5247-8b20-4372-a4e9-43f2da257303",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tweets = []\n",
    "for topic in my_topics:\n",
    "    basic_tweets.append(tweet_generation(topic, model=\"gpt-3.5-turbo\", instructions=\"\"))\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c8ca9-dd25-4a21-ab71-13511bf47521",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5e5ca-ea5a-4d81-91a8-c9995c4c5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = get_info()['export_id']\n",
    "dataset = client.load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb117ee-4a93-49cd-93f4-ae7f5b38c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e464d4-26f1-47a2-b09e-dfefac08937e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea5fab-cee7-4308-a20e-fa9610c87e22",
   "metadata": {},
   "source": [
    "## Reference-free evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bd5b1-49a1-4b1d-a4be-1faef2d4db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = [\n",
    "    TextLength(\"tweet_generation.result\", alias=\"Length\"),\n",
    "    Sentiment(\"tweet_generation.result\", alias=\"Sentiment\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83780b-798d-4bae-9433-8cf3370f0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_descriptors(descriptors=descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0cde63-b955-4a6c-8172-3ce977cf9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be69ffd-c548-4228-8c9b-f6b672342dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = Report(\n",
    "    metrics=[TextEvals()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c6d64-675a-4947-94fe-3326563dfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tweets_eval =  report.run(dataset, tags=[\"gpt-3.5-turbo\", \"simple evals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bb63f-1f3c-4c69-8e6a-f40ff6f83fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tweets_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e8475-8049-4c00-9dc8-2512b2f43398",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_run(project.id, basic_tweets_eval, include_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd0d6b-6425-4efe-a149-bacaef671c6c",
   "metadata": {},
   "source": [
    "## LLM-as-a-judge evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a2643-c37e-44da-8bfe-5b28e8ea8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1afd5d7-c97f-4b47-8103-79deaa4172b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_quality = BinaryClassificationPromptTemplate(\n",
    "    pre_messages = [(\"system\",\"You are evaluating the quality of tweets\")],\n",
    "    criteria=\"\"\"\n",
    "        Text is ENGAGING if it meets at least one of the following:\n",
    "            •        Contains a strong hook (e.g. question, surprise, bold statement)\n",
    "            •        Uses emotion, humor, or opinion\n",
    "            •        Encourages interaction (calls to action, second-person voice like “you”)\n",
    "            •        Demonstrates personality or a distinct tone\n",
    "            •        Includes vivid language, metaphors, or emojis\n",
    "            •        Sparks curiosity or gives a new insight\n",
    "\n",
    "        Text is NEUTRAL if it:\n",
    "            •        Merely states a fact or observation without emotion or opinion\n",
    "            •        Lacks clear personality, tone, or call to action\n",
    "            •        Uses generic language with no rhetorical style\n",
    "            •        Reads like an internal note, report, or placeholder\n",
    "        \"\"\",\n",
    "    target_category=\"ENGAGING\",\n",
    "    non_target_category=\"NEUTRAL\",\n",
    "    uncertainty=\"non_target\",\n",
    "    include_reasoning=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4b689-cb36-4e8b-bdce-df5398898136",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = [\n",
    "    TextLength(\"tweet_generation.result\", alias=\"Length\", tests=[lte(280)]),\n",
    "    Sentiment(\"tweet_generation.result\", alias=\"Sentiment\", tests=[gt(0.8)]),\n",
    "    LLMEval(\"tweet_generation.result\", template=tweet_quality, tests=[eq(column=\"Tweet quality\", expected=\"ENGAGING\")],\n",
    "            provider=\"openai\", model=\"gpt-4o-mini\",\n",
    "            alias=\"Tweet quality\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6a450-224a-4593-b571-841ad77875bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_descriptors(descriptors=descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6422c5-445f-4144-8fb2-4b96689da9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8884b-6458-4be7-ab34-dc9fd57d8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = Report(\n",
    "    metrics=[\n",
    "        TextEvals(column_tests={\"Length\":ValueStatsTests(max_tests=[lte(280)]),\n",
    "                                \"Sentiment\":ValueStatsTests(min_tests=[gt(0.5)]),\n",
    "                                \"Tweet quality\":ValueStatsTests(unique_values_count_tests={\"ENGAGING\":[gte(5)]})\n",
    "                                    })]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6b742-8721-4934-b5fe-32d7ee5d39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tweets_eval = report.run(dataset, tags=[\"gpt-3.5-turbo\", \"llm evals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a5fca-cc31-4be8-b0c5-4c854906a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tweets_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ebc373-f858-41d8-ba4e-b02ceb84b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_run(project.id, llm_tweets_eval, include_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3866e38-786f-4193-8d70-91de4e3acb19",
   "metadata": {},
   "source": [
    "## Improved content generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b230e1e-96fd-4de6-81b4-88b44e1dc5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_tracing(\n",
    "    project_id=str(project.id), # Project ID from Evidently Cloud\n",
    "    export_name=\"content generation: improved\",\n",
    "    as_global=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90b3976-553d-4f78-aa69-a28f5edfd1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction=\"\"\"You are a chief editor with 10 years of experience in technical writing. \n",
    "        You specialize in creating concise, engaging, and to-the-point content for engineers. \n",
    "        Your style is clear, direct, and focused on delivering technical value without fluff.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a9568-fd25-49ab-b146-f1496c1103e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_tweets = []\n",
    "for topic in my_topics:\n",
    "    improved_tweets.append(tweet_generation(topic, model=\"gpt-4o-mini\", instructions=instruction))\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae497508-0122-4761-95da-e1bcc1d2ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = get_info()['export_id']\n",
    "improved_dataset = client.load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf72f17-5dfe-4fd2-9009-76d0c7cc0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_dataset.add_descriptors(descriptors=descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7f485a-05e8-48dd-a389-2526df2ce05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_tweets_eval = report.run(improved_dataset, tags=[\"gpt-4o-mini\", \"llm evals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0b812-caea-4334-83a4-eba74bfe04f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_tweets_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf66e9d-562a-4eac-80be-5cbb1fc62b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_run(project.id, improved_tweets_eval, include_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b24dc-771d-4677-9430-d2478d0b32b7",
   "metadata": {},
   "source": [
    "## Prompt optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985cf74-b3a2-4985-b10d-72ea4101d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.llm.optimization import PromptOptimizer, Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289f3c4-64d2-4f28-b0dc-2bded41c7389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(generation_prompt: str, context):\n",
    "    \"\"\"generate engaging tweets\"\"\"\n",
    "    tweets = [tweet_generation(topic, model=\"gpt-4o-mini\", instructions=generation_prompt) for topic in my_topics]\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc4850-b8a8-4775-9f2a-6b70ec39b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = PromptOptimizer(\"tweet_gen_example\", strategy=\"feedback\")\n",
    "optimizer.set_param(Params.BasePrompt, \"You are tweet generator\")\n",
    "await optimizer.arun(run_prompt, \n",
    "                     scorer=LLMEval(\"basic_tweet_generation.result\",\n",
    "                                    template=tweet_quality,\n",
    "                                    provider=\"openai\", \n",
    "                                    model=\"gpt-4o-mini\", \n",
    "                                    alias=\"tweet quality\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739fe72-223f-4bae-aa77-6f3c5c3deae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer.best_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72eb7a-dfee-4cc4-8f16-7076636a186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_tracing(\n",
    "    project_id=str(project.id), # Project ID from Evidently Cloud\n",
    "    export_name=\"content generation: optimized\",\n",
    "    as_global=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b12b0d-bff6-41a2-a2c5-f40e0d1e273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_tweets = []\n",
    "for topic in my_topics:\n",
    "    optimized_tweets.append(tweet_generation(topic, model=\"gpt-4o-mini\", instructions=optimizer.best_prompt()))\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572540e-4524-4fdb-a9a5-a72ff21c19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = get_info()['export_id']\n",
    "optimized_dataset = client.load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c27cf0-c7e1-42b9-bfc6-e709309013ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_dataset.add_descriptors(descriptors=descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ea579-06ff-4837-9dfe-be88677b35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_tweets_eval = report.run(optimized_dataset, tags=[\"gpt-4o-mini\", \"evi optimizer\", \"llm evals\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149761ee-f24b-412d-a3a0-be2400322b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_tweets_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc488ce-42ea-4326-8a63-9ad741b937f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_run(project.id, optimized_tweets_eval, include_data=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
