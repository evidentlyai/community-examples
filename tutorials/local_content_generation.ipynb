{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab3eff6-f47f-4d94-aa8a-ecc6bc481048",
   "metadata": {},
   "source": [
    "# Evaluating LLMs on a Content Generation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf486f7-e148-466d-8e04-1845931fca87",
   "metadata": {},
   "source": [
    "* docs: https://docs.evidentlyai.com/introduction\n",
    "* repo: https://github.com/evidentlyai/evidently/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca2286-b128-4c8f-8e0b-358726dc0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install --upgrade \"openai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89fa9d-0d23-4715-a1d7-06ba481afc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee248f7-b453-46d6-90ba-7cb43f77c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a6e281-6655-4e9d-bd7a-d04cdc83b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_topics = [\n",
    "    \"testing in AI engineering is as important as in development\",\n",
    "    \"CI/CD is applicable in AI\",\n",
    "    \"Collaboration of subject matter experts and AI engineers improves product\",\n",
    "    \"Start LLM apps development from test cases generation\",\n",
    "    \"evidently is agreat for LLM testing, use it\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3fedbb-3044-449b-aeb8-3a1e8a78a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OA_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef375be3-b784-4b3e-a67f-afc15cf6d90a",
   "metadata": {},
   "source": [
    "## Basic content generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7fada1-6bf0-48dd-a9f4-72dfebb400b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = OA_client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=f\"Write a short paragraph about {my_topics[0]}\"\n",
    "    )\n",
    "\n",
    "text = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9fe36-6398-4f71-8b3c-7df23c3c4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7dca7-be90-499e-bfbe-c46d7134b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.usage.input_tokens, text.usage.output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399afa8-b388-4b52-aa46-e6ab0f156d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_tweet_generation(topic, model=\"gpt-3.5-turbo\", instructions=\"\"):\n",
    "    response = OA_client.responses.create(\n",
    "        instructions=instructions,\n",
    "        model=model,\n",
    "        input=f\"Write a short paragraph about {topic}\"\n",
    "    )\n",
    "\n",
    "    text = response.output_text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457dacc-1a69-45c8-8d77-88842bc0ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tweet_generation(my_topics[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9db106-6516-4e0a-a8a4-0d3fe82ee6dd",
   "metadata": {},
   "source": [
    "## Tracing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7b0dd-4d70-481f-8b83-90dd8e8c144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tracely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d9d9c8-fd2f-41d3-8342-4441480bef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab5b67-4052-4902-99b1-3800ce6fea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.ui.workspace import Workspace #CloudWorkspace #, RemoteWorkspace\n",
    "\n",
    "from evidently import Dataset, DataDefinition, Report\n",
    "from evidently.descriptors import *\n",
    "from evidently.presets import TextEvals\n",
    "from evidently.llm.templates import BinaryClassificationPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061ad24-6667-476e-a732-b4807371bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracely import init_tracing, get_info\n",
    "from tracely import trace_event, get_current_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d38f08-f197-4f76-9f1d-e597fc6edeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Workspace(path='workspace')\n",
    "#client = CloudWorkspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59825687-fdad-4d51-b26d-248cc1ba8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = client.create_project(name=\"Content evals\")\n",
    "#project = client.create_project(\"Content Generation: evals & optimization\",  \n",
    "#                                org_id = \"ORG ID HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ba3a5-3f59-425a-b967-f3d627efe68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_tracing(\n",
    "    address=\"http://localhost:8000/\",\n",
    "    project_id=project.id, \n",
    "    export_name=\"basic content generation\",\n",
    "    as_global=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae41329-f66f-48a1-b778-6cb179e1ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace_event()\n",
    "def tweet_generation(topic, model=\"gpt-3.5-turbo\", instructions=\"\"):\n",
    "    response = OA_client.responses.create(\n",
    "        instructions=instructions,\n",
    "        model=model,\n",
    "        input=f\"Write a short paragraph about {topic}\"\n",
    "    )\n",
    "\n",
    "    span = get_current_span()\n",
    "    span.update_usage(\n",
    "        tokens={\n",
    "            \"input\": response.usage.input_tokens,\n",
    "            \"output\": response.usage.output_tokens,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    text = response.output_text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcfeac6-7a98-4983-99cb-dff5d2065641",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tweets = [tweet_generation(topic, model=\"gpt-3.5-turbo\", instructions=\"\") for topic in my_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c8ca9-dd25-4a21-ab71-13511bf47521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basic_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8272ac-d8c8-4fca-9b37-9160a47f1b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5e5ca-ea5a-4d81-91a8-c9995c4c5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = get_info()['export_id']\n",
    "dataset = client.load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb117ee-4a93-49cd-93f4-ae7f5b38c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e464d4-26f1-47a2-b09e-dfefac08937e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1afd5d7-c97f-4b47-8103-79deaa4172b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_quality = BinaryClassificationPromptTemplate(\n",
    "    pre_messages = [(\"system\",\"You are evaluating the quality of tweets\")],\n",
    "    criteria=\"\"\"\n",
    "        Text is ENGAGING if it meets at least one of the following:\n",
    "            •        Contains a strong hook (e.g. question, surprise, bold statement)\n",
    "            •        Uses emotion, humor, or opinion\n",
    "            •        Encourages interaction (calls to action, second-person voice like “you”)\n",
    "            •        Demonstrates personality or a distinct tone\n",
    "            •        Includes vivid language, metaphors, or emojis\n",
    "            •        Sparks curiosity or gives a new insight\n",
    "\n",
    "        Text is NEUTRAL if it:\n",
    "            •        Merely states a fact or observation without emotion or opinion\n",
    "            •        Lacks clear personality, tone, or call to action\n",
    "            •        Uses generic language with no rhetorical style\n",
    "            •        Reads like an internal note, report, or placeholder\n",
    "        \"\"\",\n",
    "    target_category=\"ENGAGING\",\n",
    "    non_target_category=\"NEUTRAL\",\n",
    "    uncertainty=\"non_target\",\n",
    "    include_reasoning=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4b689-cb36-4e8b-bdce-df5398898136",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = [\n",
    "    TextLength(\"tweet_generation.result\", alias=\"Length\"),\n",
    "    Sentiment(\"tweet_generation.result\", alias=\"Sentiment\"),\n",
    "    LLMEval(\"tweet_generation.result\", template=tweet_quality,\n",
    "           provider=\"openai\", model=\"gpt-4o-mini\",\n",
    "           alias=\"Tweet quality\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6a450-224a-4593-b571-841ad77875bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_descriptors(descriptors=descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6422c5-445f-4144-8fb2-4b96689da9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8884b-6458-4be7-ab34-dc9fd57d8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = Report(\n",
    "    metrics=[TextEvals()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6b742-8721-4934-b5fe-32d7ee5d39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tweets_eval = report.run(dataset, tags=[\"gpt-3.5-turbo\", \"basic generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48438680-9214-4f27-a016-e7aad217ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tweets_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ebc373-f858-41d8-ba4e-b02ceb84b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_run(project.id, basic_tweets_eval, include_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb864f-bfb3-4240-9541-f87ebcb15862",
   "metadata": {},
   "source": [
    "## Prompt Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4621a-1d2d-4c0e-ae88-27157a3a04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.llm.optimization import PromptOptimizer, PromptExecutionLog, Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb717c-c098-4439-9547-7b2d9134be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(generation_prompt: str, context) -> pd.Series:\n",
    "    \"\"\"generate engaging tweets\"\"\"\n",
    "    my_topics = [\n",
    "        \"testing in AI engineering is as important as in development\",\n",
    "        \"CI/CD is applicable in AI\",\n",
    "        \"Collaboration of subject matter experts and AI engineers improves product\",\n",
    "        \"Start LLM apps development from test cases generation\",\n",
    "        \"evidently is a great tool for LLM testing\"\n",
    "    ]\n",
    "    tweets = [basic_tweet_generation(topic, model=\"gpt-3.5-turbo\", instructions=generation_prompt) for topic in my_topics]\n",
    "    return pd.Series(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad5dd9-edf0-44bc-be73-813b1eea30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = LLMEval(\"tweet_generation.result\", template=tweet_quality,\n",
    "                provider=\"openai\", model=\"gpt-4o-mini\", alias=\"Tweet quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0711e7-8266-493d-92a3-0af629d629cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = PromptOptimizer(\"tweet_gen_example\", strategy=\"feedback\", verbose=True)\n",
    "await optimizer.arun(run_prompt, scorer=judge, base_prompt=\"You are tweet generator\", repetitions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4902c0b-07b0-4d67-bf37-d5185d4e35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer.best_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d47bff5-d585-43f7-abad-33e9db6ddf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f29a5-c240-4c79-aa9a-40bdd0088d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_tracing(\n",
    "    address=\"http://localhost:8000/\",\n",
    "    project_id=project.id, # Project ID from Evidently Cloud\n",
    "    export_name=\"optimised content generation\",\n",
    "    as_global=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cbe240-74d8-4312-8ff4-958476d5037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_tweets = [tweet_generation(topic, model=\"gpt-4o-mini\", instructions=optimizer.best_prompt()) for topic in my_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf04ac-02da-4b29-87f9-ae6c27253bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10022472-f00f-46cc-af5a-616b677db9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = get_info()['export_id']\n",
    "optimized_dataset = client.load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227ed60-c197-44b5-8407-2088637d4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_dataset.add_descriptors(descriptors=descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137f057b-8dbc-405d-9c9f-fa7b09d690b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_dataset.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332de01-bb20-4a65-a968-8cfeaf360552",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_tweets_eval = report.run(optimized_dataset, tags=[\"gpt-4o-mini\", \"optimized generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5f195-3d4e-4626-b049-05991ee3aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_tweets_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf17ee5-02d5-4b4b-a770-edb041b06f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_run(project.id, optimized_tweets_eval, include_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89edc8ac-72e9-454f-a067-d07e3b47e874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
