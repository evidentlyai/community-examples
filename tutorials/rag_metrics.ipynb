{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install evidently[llm]"
      ],
      "metadata": {
        "id": "XAMLWWa_2zAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
"cell_type": "code",
"source": [
    "import pandas as pd\n",
    "\n",
    "from evidently import Dataset\n",
    "from evidently import DataDefinition\n",
    "from evidently.descriptors import *\n",
    "\n",
    "from evidently import Report\n",
    "from evidently.presets import TextEvals\n",
    "from evidently.metrics import *\n",
    "from evidently.tests import *\n",
    "\n",
    "from evidently.ui.workspace import CloudWorkspace"
],
      "metadata": {
        "id": "wHmYsdct7NoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokens"
      ],
      "metadata": {
        "id": "m4KoYJG1zIHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\""
      ],
      "metadata": {
        "id": "9gSoXkFbbDZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ws = CloudWorkspace(token=\"YOUR_API_TOKEN\", url=\"https://app.evidently.cloud\")"
      ],
      "metadata": {
        "id": "4meDVdzb8Ox4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Project"
      ],
      "metadata": {
        "id": "RZbWKzqrzSTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# project = ws.create_project(\"My test project\", org_id=\"YOUR_ORG_ID\")\n",
        "# project.description = \"My project description\"\n",
        "# project.save()\n",
        "\n",
        "# or project = ws.get_project(\"PROJECT_ID\")"
      ],
      "metadata": {
        "id": "5SpbFDfe8S7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval - Single context"
      ],
      "metadata": {
        "id": "4HVOY2soztLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data = [\n",
        "\n",
        "    [\"Why do flowers bloom in spring?\",\n",
        "     \"Plants require extra care during cold months. You should keep them indoors.\",\n",
        "     \"because of the rising temperatures\"],\n",
        "\n",
        "    [\"Why do we yawn when we see someone else yawn?\",\n",
        "     \"Yawning is contagious due to social bonding and mirror neurons in our brains that trigger the response when we see others yawn.\",\n",
        "     \"because it's a glitch in the matrix\"],\n",
        "\n",
        "    [\"How far is Saturn from Earth?\",\n",
        "     \"The distance between Earth and Saturn varies, but on average, Saturn is about 1.4 billion kilometers (886 million miles) away from Earth.\",\n",
        "     \"about 1.4 billion kilometers\"],\n",
        "\n",
        "    [\"Where do penguins live?\",\n",
        "     \"Penguins primarily live in the Southern Hemisphere, with most species found in Antarctica, as well as on islands and coastlines of South America, Africa, Australia, and New Zealand.\",\n",
        "     \"mostly in Antarctica and southern regions\"],\n",
        "]\n",
        "\n",
        "columns = [\"Question\", \"Context\", \"Response\"]\n",
        "synthetic_df = pd.DataFrame(synthetic_data, columns=columns)"
      ],
      "metadata": {
        "id": "GWK1DBORIL_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "Hysc1JRsz285"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ContextQuality"
      ],
      "metadata": {
        "id": "gv4ANZCsLz3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_based_evals = Dataset.from_pandas(\n",
        "    pd.DataFrame(synthetic_df),\n",
        "    data_definition=DataDefinition(\n",
        "        text_columns=[\"Question\", \"Context\", \"Response\"],\n",
        "    ),\n",
        "    descriptors=[\n",
        "        ContextQualityLLMEval(\"Context\", question=\"Question\"),\n",
        "    ]\n",
        ")\n",
        "context_based_evals.as_dataframe()"
      ],
      "metadata": {
        "id": "k5ccKrpkJs8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ContextRelevance"
      ],
      "metadata": {
        "id": "vrZ5ftRuqof_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_based_evals = Dataset.from_pandas(\n",
        "    pd.DataFrame(synthetic_df),\n",
        "    data_definition=DataDefinition(\n",
        "        text_columns=[\"Question\", \"Context\", \"Response\"],\n",
        "    ),\n",
        "    descriptors=[\n",
        "        ContextRelevance(\"Question\", \"Context\",\n",
        "                                  output_scores=True,\n",
        "                                  aggregation_method=\"hit\",\n",
        "                                  method=\"llm\",\n",
        "                                  alias=\"Hit\"\n",
        "                                  )\n",
        "    ]\n",
        ")\n",
        "context_based_evals.as_dataframe()"
      ],
      "metadata": {
        "id": "AkRKfjssqn-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval - Multi context"
      ],
      "metadata": {
        "id": "H2CCU_haLvi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data = [\n",
        "    [\"Why are bananas healthy?\",\n",
        "     [\"Bananas are rich in potassium and vitamins, making them good for heart health.\",\n",
        "      \"Bananas provide quick energy due to natural sugars.\",\n",
        "      \"Are bananas actually a vegetable?\"],\n",
        "     \"because they are rich in nutrients\"],\n",
        "\n",
        "    [\"How do you cook potatoes?\",\n",
        "     [\"Potatoes are easy to grow.\",\n",
        "      \"The best way to cook potatoes is to eat them raw.\",\n",
        "      \"Can potatoes be cooked in space?\"],\n",
        "     \"boil, bake, or fry them\"],\n",
        "]\n",
        "\n",
        "# Create a DataFrame\n",
        "columns = [\"Question\", \"Context\", \"Response\"]\n",
        "synthetic_df_2 = pd.DataFrame(synthetic_data, columns=columns)\n"
      ],
      "metadata": {
        "id": "rOaSVULINP9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ContextRelevance, Hit"
      ],
      "metadata": {
        "id": "DSWUKa0TqXA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_based_evals = Dataset.from_pandas(\n",
        "    pd.DataFrame(synthetic_df_2),\n",
        "    data_definition=DataDefinition(\n",
        "        text_columns=[\"Question\", \"Context\", \"Response\"],\n",
        "    ),\n",
        "    descriptors=[\n",
        "        ContextRelevance(\"Question\", \"Context\",\n",
        "                                  output_scores=True,\n",
        "                                  aggregation_method=\"hit\",\n",
        "                                  method=\"llm\",\n",
        "                                  alias=\"Hit\"\n",
        "                                  )\n",
        "    ]\n",
        ")\n",
        "context_based_evals.as_dataframe()"
      ],
      "metadata": {
        "id": "Toga39jdRg2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ContextRelevance, Mean"
      ],
      "metadata": {
        "id": "LpFuF85UqYp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_based_evals = Dataset.from_pandas(\n",
        "    pd.DataFrame(synthetic_df_2),\n",
        "    data_definition=DataDefinition(\n",
        "        text_columns=[\"Question\", \"Context\", \"Response\"],\n",
        "    ),\n",
        "    descriptors=[\n",
        "        ContextRelevance(\"Question\", \"Context\",\n",
        "                                  output_scores=True,\n",
        "                                  aggregation_method=\"mean\",\n",
        "                                  method=\"llm\",\n",
        "                                  alias=\"Relevance\"\n",
        "                                  )\n",
        "    ]\n",
        ")\n",
        "context_based_evals.as_dataframe()"
      ],
      "metadata": {
        "id": "nGyJuHNomT0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation - ground truth"
      ],
      "metadata": {
        "id": "W0I2wIVKJgeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data = [\n",
        "    [\"Why do we yawn when we see someone else yawn?\",\n",
        "     \"because it's a glitch in the matrix.\",\n",
        "     \"Due to social bonding and mirror neurons in our brains.\"],\n",
        "\n",
        "    [\"Why do flowers bloom in spring?\",\n",
        "     \"Because of the the rising temperatures.\",\n",
        "     \"Because it is getting warmer.\"],\n",
        "\n",
        "    [\"Why are bananas healthy?\",\n",
        "     \"Because they are rich in nutrients.\",\n",
        "     \"Because they contain a lot of nutrients.\"]\n",
        "]\n",
        "\n",
        "columns = [\"Question\", \"Response\", \"Target\"]\n",
        "synthetic_df_4 = pd.DataFrame(synthetic_data, columns=columns)"
      ],
      "metadata": {
        "id": "KKic4gRXwvn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_based_evals = Dataset.from_pandas(\n",
        "    pd.DataFrame(synthetic_df_4),\n",
        "    data_definition=DataDefinition(\n",
        "        text_columns=[\"Question\", \"Response\", \"Target\"],\n",
        "    ),\n",
        "    descriptors=[\n",
        "        CorrectnessLLMEval(\"Response\", target_output=\"Target\"),\n",
        "        BERTScore(columns=[\"Response\", \"Target\"], alias=\"BERTScore\"),\n",
        "        SemanticSimilarity(columns=[\"Response\", \"Target\"], alias=\"Semantic Similarity\"),\n",
        "    ]\n",
        ")\n",
        "context_based_evals.as_dataframe()"
      ],
      "metadata": {
        "id": "HpKqYYfhxqoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation - open-ended"
      ],
      "metadata": {
        "id": "pMDFkWRkJZSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_based_evals = Dataset.from_pandas(\n",
        "    pd.DataFrame(synthetic_df),\n",
        "    data_definition=DataDefinition(\n",
        "        text_columns=[\"Question\", \"Context\", \"Response\"],\n",
        "    ),\n",
        "    descriptors=[\n",
        "        FaithfulnessLLMEval(\"Response\", context=\"Context\")\n",
        "    ]\n",
        ")\n",
        "context_based_evals.as_dataframe()"
      ],
      "metadata": {
        "id": "-LhQR1Rkzsxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report"
      ],
      "metadata": {
        "id": "tU5acjQM3yRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine ContextQuality and faithfulness:"
      ],
      "metadata": {
        "id": "JqqpwG6hPZaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_based_evals = Dataset.from_pandas(\n",
        "    pd.DataFrame(synthetic_df),\n",
        "    data_definition=DataDefinition(\n",
        "        text_columns=[\"Question\", \"Context\", \"Response\"],\n",
        "    ),\n",
        "    descriptors=[\n",
        "        FaithfulnessLLMEval(\"Response\", context=\"Context\"),\n",
        "        ContextQualityLLMEval(\"Context\", question=\"Question\"),\n",
        "    ]\n",
        ")\n",
        "# context_based_evals.as_dataframe()"
      ],
      "metadata": {
        "id": "b-wLZxWH5Uw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = Report([\n",
        "    TextEvals()\n",
        "])\n",
        "\n",
        "my_eval = report.run(context_based_evals, None)\n",
        "my_eval"
      ],
      "metadata": {
        "id": "ueQRqHC15oyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Tests"
      ],
      "metadata": {
        "id": "ku23maBfEnUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report = Report([\n",
        "    TextEvals(),\n",
        "    CategoryCount(column=\"Faithfulness\", category=\"UNFAITHFUL\", tests=[eq(0)]),\n",
        "    CategoryCount(column=\"ContextQuality\", category=\"INVALID\", tests=[eq(0)])\n",
        "])\n",
        "\n",
        "my_eval = report.run(context_based_evals, None)\n",
        "my_eval"
      ],
      "metadata": {
        "id": "DA1gWZjkj0nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload to Cloud"
      ],
      "metadata": {
        "id": "hB6XH2o3xU4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ws.add_run(project.id, my_eval, include_data=True)"
      ],
      "metadata": {
        "id": "48t7dW472ELK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
