{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Disclaimer**. This example uses the Evidently API as available in version 0.6.7 or lower. Please ensure you are using the correct version when running this notebook. For updated and new examples using the latest Evidently versions, visit our documentation. \n",
        "\n",
        "Evidently docs: https://docs.evidentlyai.com/\n",
        "\n",
        "Join our Discord: https://discord.com/invite/xZjKRaNp8b"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6eM1BMvDwgee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evidently==0.4.0"
      ],
      "metadata": {
        "id": "LcuCpnwq_OTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "id": "gRCETcmTUM2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and support functions"
      ],
      "metadata": {
        "id": "g2Wm7fyUJgCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import random"
      ],
      "metadata": {
        "id": "kstcCrLYJlJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "m4DldPK7Jwhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "metadata": {
        "id": "F2mGqM_UJmuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evidently.pipeline.column_mapping import ColumnMapping\n",
        "\n",
        "from evidently.report import Report\n",
        "from evidently.metric_preset import DataDriftPreset, TargetDriftPreset\n",
        "from evidently.metric_preset import ClassificationPreset\n",
        "from evidently.metrics import ClassificationQualityMetric, TextDescriptorsDriftMetric, ColumnDriftMetric"
      ],
      "metadata": {
        "id": "6UbTvcjWJ4hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "qVcOsoGQK4PJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will work with a dataset that contains reviews and ratings for different drugs."
      ],
      "metadata": {
        "id": "mukd-AcEK9sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\").content\n",
        "with zipfile.ZipFile(io.BytesIO(content)) as arc:\n",
        "    raw_data = pd.read_csv(arc.open(\"drugsComTest_raw.tsv\"), sep='\\t')\n",
        "\n",
        "raw_data = raw_data[['drugName', 'condition', 'review',\t'rating']]"
      ],
      "metadata": {
        "id": "wgt0CmMj1C3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data source: https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29\n",
        "\n",
        "Citation:\n",
        "Felix Gräßer, Surya Kallumadi, Hagen Malberg, and Sebastian Zaunseder. 2018. Aspect-Based Sentiment Analysis of Drug Reviews Applying Cross-Domain and Cross-Data Learning. In Proceedings of the 2018 International Conference on Digital Health (DH '18). ACM, New York, NY, USA, 121-125. DOI: [Web Link]"
      ],
      "metadata": {
        "id": "jGZHTfiBViAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.head()"
      ],
      "metadata": {
        "id": "0TQPDqoQ1uaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and testing the model"
      ],
      "metadata": {
        "id": "U0SwHiH54h3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we want to build a model to distinguish between reviews with rating 1 (negative review) and 10 (positive review). Let's also assume that we only have access to reviews on pain medications."
      ],
      "metadata": {
        "id": "eoxu9017L70k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_data = raw_data.loc[(raw_data['condition'] == 'Pain') & (raw_data['rating'].isin([1, 10])), ['review', 'rating']]\n",
        "init_data['is_positive'] = init_data['rating'].apply(lambda x: 0 if x == 1 else 1)\n",
        "init_data.drop(['rating'], inplace=True, axis=1)\n",
        "init_data.head()"
      ],
      "metadata": {
        "id": "tn3PAtpj4lNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the data into \"reference\" and \"valid\" datasets. Reference dataset is used for training while 40% of the data is held out for model validation"
      ],
      "metadata": {
        "id": "U38mO2TAN-Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(init_data['review'], init_data['is_positive'],\n",
        "                                                    test_size=0.4, random_state=42, shuffle=True)\n",
        "\n",
        "reference = pd.DataFrame({'review': X_train, 'is_positive': y_train})\n",
        "valid = pd.DataFrame({'review': X_test, 'is_positive': y_test})"
      ],
      "metadata": {
        "id": "_oFVsQBv62Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a model with TF-IDF vectorization and linear classifier on top"
      ],
      "metadata": {
        "id": "tXLbdHEnOnRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(\n",
        "    [\n",
        "        (\"vectorization\", TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words=\"english\")),\n",
        "        (\"classification\", SGDClassifier(alpha=0.0001, max_iter=50, penalty='l1', loss='modified_huber', random_state=42))\n",
        "        ])\n",
        "pipeline.fit(reference['review'].values, reference['is_positive'].values)"
      ],
      "metadata": {
        "id": "Dr9Qlun_7LqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate model predictions for training and validation datasets. Our model predicts the probability of a review being positive"
      ],
      "metadata": {
        "id": "-d7X8PsDO7fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference['predict_proba'] = pipeline.predict_proba(reference['review'].values)[:,1]\n",
        "valid['predict_proba'] = pipeline.predict_proba(valid['review'].values)[:,1]"
      ],
      "metadata": {
        "id": "1Kbopctq7k1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up column mapping\n",
        "column_mapping = ColumnMapping()\n",
        "\n",
        "column_mapping.target = 'is_positive'\n",
        "column_mapping.prediction = 'predict_proba'\n",
        "column_mapping.text_features = ['review']\n",
        "\n",
        "# list features so text field is not treated as a regular feature\n",
        "column_mapping.numerical_features = []\n",
        "column_mapping.categorical_features = []"
      ],
      "metadata": {
        "id": "61ZOAQw58q4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model accuracy on validation dataset is a bit higher than 0.8. This is the level of performance we can expect on similar new data"
      ],
      "metadata": {
        "id": "xExX1rHPPgpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "performance_report = Report(metrics=[\n",
        "    ClassificationQualityMetric()\n",
        "])\n",
        "\n",
        "performance_report.run(reference_data=reference, current_data=valid,\n",
        "                        column_mapping=column_mapping)\n",
        "performance_report"
      ],
      "metadata": {
        "id": "n5PqmKOw85r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data drift due to \"technical issues\""
      ],
      "metadata": {
        "id": "cmcHWJeLQ2e2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagine that after deploying the model something changes at the data collecting stage. Could be that on-line data preprocessing differs from historical one or that some odd update simply breaks data cleaning steps.\n",
        "\n",
        "Let's see what happens if we either inject some random html tags in the review text or translate the review to French."
      ],
      "metadata": {
        "id": "CxXpm1AgQ_xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "\n",
        "def translate_str(s):\n",
        "  return translator.translate(s, dest='fr').text\n",
        "\n",
        "random_html_tags = ('<body>, </body>', '<html><body>', '</body></html>', '<h1>', '</h1>',\n",
        "                    '<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 0 0\" width=\"0\" height=\"0\" focusable=\"false\" role=\"none\" style=\"visibility: hidden; position: absolute; left: -9999px; overflow: hidden;\"><defs><filter id=\"wp-duotone-magenta-yellow\"><feColorMatrix color-interpolation-filters=\"sRGB\" type=\"matrix\" values=\" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 \"></feColorMatrix><feComponentTransfer color-interpolation-filters=\"sRGB\"><feFuncR type=\"table\" tableValues=\"0.78039215686275 1\"></feFuncR><feFuncG type=\"table\" tableValues=\"0 0.94901960784314\"></feFuncG><feFuncB type=\"table\" tableValues=\"0.35294117647059 0.47058823529412\"></feFuncB><feFuncA type=\"table\" tableValues=\"1 1\"></feFuncA></feComponentTransfer><feComposite in2=\"SourceGraphic\" operator=\"in\"></feComposite></filter></defs></svg>')\n",
        "\n",
        "def inject_random_html_tags(s):\n",
        "  num_tags = 25\n",
        "  for i in range(num_tags):\n",
        "    random.seed(i)\n",
        "    pos = random.choice(range(len(s)))\n",
        "    s = s[:pos] + random.choice(random_html_tags) + s[pos:]\n",
        "\n",
        "  return s"
      ],
      "metadata": {
        "id": "ys8RG24FTuAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_disturbed = valid[['review', 'is_positive']]"
      ],
      "metadata": {
        "id": "Mierji-ZOYhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disturbed_num = int(len(valid_disturbed) * 0.5)\n",
        "random.seed(42)\n",
        "disturbed_ind = random.sample(list(valid_disturbed.index), k=disturbed_num)\n",
        "valid_disturbed.loc[disturbed_ind[:int(disturbed_num / 10)], 'review'] = \\\n",
        "valid_disturbed.loc[disturbed_ind[:int(disturbed_num / 10)], 'review'].apply(inject_random_html_tags)\n",
        "valid_disturbed.loc[disturbed_ind[int(disturbed_num / 10):], 'review'] = \\\n",
        "valid_disturbed.loc[disturbed_ind[int(disturbed_num / 10):], 'review'].apply(translate_str)"
      ],
      "metadata": {
        "id": "lJqzSPg_O8nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_disturbed['predict_proba'] = pipeline.predict_proba(valid_disturbed['review'].values)[:,1]"
      ],
      "metadata": {
        "id": "sTaent8yp_3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_report = Report(metrics=[\n",
        "    ClassificationQualityMetric()\n",
        "])\n",
        "\n",
        "performance_report.run(reference_data=valid, current_data=valid_disturbed,\n",
        "                        column_mapping=column_mapping)\n",
        "performance_report"
      ],
      "metadata": {
        "id": "7MeMiL0KUf7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oops! Model accuracy has dropped. Let's look at the Data Drift report to see why"
      ],
      "metadata": {
        "id": "D2STHFwwWxXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "yXWI5SeoSKME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_drift_report = Report(\n",
        "    metrics=[\n",
        "        ColumnDriftMetric('is_positive'),\n",
        "        ColumnDriftMetric('predict_proba'),\n",
        "        TextDescriptorsDriftMetric(column_name='review'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "data_drift_report.run(reference_data=reference,\n",
        "                      current_data=valid_disturbed,\n",
        "                      column_mapping=column_mapping)\n",
        "data_drift_report"
      ],
      "metadata": {
        "id": "RJSXCrsvRFCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see the culprit: new (perturbed) dataset contains considerably more suspiciously long reviews and reviews with a lot of OOV (out-of-vocabulary) words\n",
        "\n",
        "If we look at the examples of such reviews we see the problems right away:\n",
        "\n",
        "*   HTML tags not being removed from the texts properly\n",
        "*   Reviews in a new unexpected language\n",
        "\n"
      ],
      "metadata": {
        "id": "D4LDVly9ZLFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evidently.features.text_length_feature import TextLength\n",
        "from evidently.features.OOV_words_percentage_feature import OOVWordsPercentage"
      ],
      "metadata": {
        "id": "hbhFVlkfZmGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_feature = TextLength(column_name='review').generate_feature(data=valid_disturbed, data_definition=None)\n",
        "oov_feature = OOVWordsPercentage(column_name='review').generate_feature(data=valid_disturbed, data_definition=None)"
      ],
      "metadata": {
        "id": "u72x-JgMauJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_disturbed['text_length'] = text_feature.values\n",
        "valid_disturbed['oov_share'] = oov_feature.values"
      ],
      "metadata": {
        "id": "f7IigmqUbUQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_disturbed[valid_disturbed['text_length'] > 1000].head()"
      ],
      "metadata": {
        "id": "WFSWuTYnab-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_disturbed[valid_disturbed['text_length'] > 1000].iloc[0, 0]"
      ],
      "metadata": {
        "id": "m4Orn-ijuxz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_disturbed[valid_disturbed['oov_share'] > 30].head()"
      ],
      "metadata": {
        "id": "edpfz1JAYlPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_drift_dataset_report = Report(metrics=[\n",
        "    ColumnDriftMetric(column_name='review')\n",
        "])\n",
        "\n",
        "data_drift_dataset_report.run(reference_data=reference,\n",
        "                              current_data=valid_disturbed,\n",
        "                              column_mapping=column_mapping)\n",
        "data_drift_dataset_report"
      ],
      "metadata": {
        "id": "0UpODLswFPr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Content drift"
      ],
      "metadata": {
        "id": "VePLsS-P-s3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technical issues sorted out, the model continues to be used for reviews' sentiment analysis. Suppose we decide to apply it on reviews for antidepressants."
      ],
      "metadata": {
        "id": "n2n9eSx2akjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_content = raw_data.loc[(raw_data['condition'] == 'Depression') & (raw_data['rating'].isin([1, 10])), ['review', 'rating']]\n",
        "new_content['is_positive'] = new_content['rating'].apply(lambda x: 0 if x == 1 else 1)\n",
        "new_content.drop(['rating'], inplace=True, axis=1)\n",
        "new_content.head()"
      ],
      "metadata": {
        "id": "6SJlPB80-4bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_content['predict_proba'] = pipeline.predict_proba(new_content['review'].values)[:,1]"
      ],
      "metadata": {
        "id": "f6Fj7emu_U2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_report = Report(metrics=[\n",
        "    ClassificationQualityMetric(),\n",
        "])\n",
        "\n",
        "performance_report.run(reference_data=valid, current_data=new_content,\n",
        "                        column_mapping=column_mapping)\n",
        "performance_report"
      ],
      "metadata": {
        "id": "5gJkUeAT_jeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, model's performance is worse than expected. Let's look at the Data Drift report"
      ],
      "metadata": {
        "id": "39IVND7CgPJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_drift_report = Report(\n",
        "    metrics=[\n",
        "        ColumnDriftMetric('is_positive'),\n",
        "        ColumnDriftMetric('predict_proba'),\n",
        "        TextDescriptorsDriftMetric(column_name='review'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "data_drift_report.run(reference_data=reference,\n",
        "                      current_data=new_content,\n",
        "                      column_mapping=column_mapping)\n",
        "data_drift_report"
      ],
      "metadata": {
        "id": "-B6zOYVvgta0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there's drift in the data. Reviews tend to be longer for the current dataset and OOV words are encountered more often. But nothing as obvious as in the case above.\n",
        "\n",
        "The problem is that it's the reviews *content* that drifted. Let's see how Evidently can help to detect such a change"
      ],
      "metadata": {
        "id": "LHjR3uX_hIMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To detect content drift Evidently uses domain classifier approach. A classifier is trained that tries to predict whether a text is from a reference dataset or from a new dataset. If it can be done successfully than the new dataset is significantly different from the reference one.\n",
        "\n",
        "If content data drift is detected Evidently also provides some insights on the nature of the drift:\n",
        "* Words that are more distinctive of the current vs reference dataset.\n",
        "These are the words that are the most informative for the domain classifier when it predicts if a text came from the reference or from the current dataset\n",
        "* Examples of texts that are more distinctive of the current vs reference dataset. These examples were the easiest for a classifier to label correctly"
      ],
      "metadata": {
        "id": "exLUYNjSish0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_drift_dataset_report = Report(metrics=[\n",
        "    ColumnDriftMetric(column_name='review')\n",
        "])\n",
        "\n",
        "data_drift_dataset_report.run(reference_data=reference,\n",
        "                              current_data=new_content,\n",
        "                              column_mapping=column_mapping)\n",
        "data_drift_dataset_report\n"
      ],
      "metadata": {
        "id": "OQYdNSdr__8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At once we can see how the current dataset differs from the reference dataset our model was trained on. Current dataset is characterized with words and examples about depression, mood and popular antidepressants while the reference dataset is more about pain, shock symptoms and popular painkillers"
      ],
      "metadata": {
        "id": "vQkPoRfWk1g8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that no such drift is detected for validation dataset that consists of reviews for painkillers, similar to reference dataset"
      ],
      "metadata": {
        "id": "eQT3ylM9l8j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_drift_dataset_report = Report(metrics=[\n",
        "    ColumnDriftMetric(column_name='review')\n",
        "])\n",
        "\n",
        "data_drift_dataset_report.run(reference_data=reference,\n",
        "                              current_data=valid,\n",
        "                              column_mapping=column_mapping)\n",
        "data_drift_dataset_report"
      ],
      "metadata": {
        "id": "Cs6C7qpeAvmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the solutions to deal with this kind of data change is to retrain the model on a dataset that includes new relevant data. With Evidently it can be done *proactively* by detecting data drift even before information on target labels and model performance is collected"
      ],
      "metadata": {
        "id": "gWgExmA1mn9t"
      }
    }
  ]
}
